{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from scipy.signal import resample\n",
    "\n",
    "# 필요한 상수 정의\n",
    "SAMPLE_RATE = 16000\n",
    "FOLDER_NAME = \"data\"  # csv파일 생성할 폴더 이름\n",
    "RESULTS_FILE_NAME = \"voyager_test_results\" # test 결과 파일\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_file():\n",
    "  file_name = open(f'202301ml_fmcc/fmcc_test_ref.txt', 'r')\n",
    "  test_data_list = []\n",
    "  label_list = []\n",
    "\n",
    "  for i in file_name.readlines():\n",
    "    file, label = i.strip('\\n').split(' ')\n",
    "    \n",
    "    f = open(f'202301ml_fmcc/raw16k/test/' + file + '.raw', 'rb')\n",
    "    file = np.fromfile(f, dtype='int16', sep=\"\")\n",
    "    \n",
    "    test_data_list.append(file.astype(np.float32))\n",
    "    label_list.append(0 if label[0] == 'm' else 1)\n",
    "    \n",
    "  return test_data_list, label_list\n",
    "\n",
    "def get_train_file():\n",
    "  file_name = open(f'202301ml_fmcc/fmcc_train.ctl', 'r')\n",
    "  train_data_list = []\n",
    "  label_list = []\n",
    "  for i in file_name.readlines():\n",
    "    i = i.strip('\\n')\n",
    "    f = open(f'202301ml_fmcc/raw16k/train/' + i + '.raw', 'rb')\n",
    "    file = np.fromfile(f, dtype='int16', sep=\"\")\n",
    "    \n",
    "    train_data_list.append(file.astype(np.float32))\n",
    "    label_list.append(0 if i[0] == 'M' else 1)\n",
    "        \n",
    "    # add_noise_audio = file.astype(np.float32)\n",
    "    # noise = np.random.normal(0, 500, add_noise_audio.shape)\n",
    "\n",
    "    #원본 음성 데이터에 노이즈 추가\n",
    "    # noisy_signal = add_noise_audio + noise\n",
    "    # train_data_list.append(noisy_signal)\n",
    "    # label_list.append(0 if i[0] == 'M' else 1)\n",
    "    \n",
    "    # extended_audio = file.astype(np.float32)\n",
    "    # train_data_list.append(resample(extended_audio, int(len(extended_audio) / 2)))\n",
    "    # label_list.append(0 if i[0] == 'M' else 1)\n",
    "    \n",
    "  return train_data_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(data): \n",
    "    ft1 = librosa.feature.mfcc(y=data, sr=SAMPLE_RATE, n_mfcc=20, fmin=0.0, fmax=500.0)\n",
    "    # ft2 = librosa.feature.zero_crossing_rate(y = data)[0]\n",
    "    # ft3 = librosa.feature.spectral_rolloff(y = data)[0]\n",
    "    # ft4 = librosa.feature.spectral_centroid(y = data)[0]\n",
    "    # ft5 = librosa.feature.spectral_contrast(y = data)[0]\n",
    "    # ft6 = librosa.feature.spectral_bandwidth(y = data)[0]\n",
    "    ft1_trunc = np.hstack((np.mean(ft1, axis=1), np.std(ft1, axis=1), skew(ft1, axis = 1), kurtosis(ft1, axis=1), np.max(ft1, axis=1), np.median(ft1, axis=1), np.min(ft1, axis=1)))\n",
    "    # ft2_trunc = np.hstack((np.mean(ft2), np.std(ft2), skew(ft2), np.max(ft2), np.median(ft2), np.min(ft2)))\n",
    "    # ft3_trunc = np.hstack((np.mean(ft3), np.std(ft3), skew(ft3), np.max(ft3), np.median(ft3), np.min(ft3)))\n",
    "    # ft4_trunc = np.hstack((np.mean(ft4), np.std(ft4), skew(ft4), np.max(ft4), np.median(ft4), np.min(ft4)))\n",
    "    # ft5_trunc = np.hstack((np.mean(ft5), np.std(ft5), skew(ft5), np.max(ft5), np.median(ft5), np.min(ft5)))\n",
    "    # ft6_trunc = np.hstack((np.mean(ft6), np.std(ft6), skew(ft6), np.max(ft6), np.median(ft6), np.max(ft6)))\n",
    "    # return pd.Series(np.hstack((ft1_trunc, ft2_trunc, ft3_trunc, ft4_trunc, ft5_trunc, ft6_trunc)))\n",
    "    return pd.Series(np.hstack((ft1_trunc,)))\n",
    "    \n",
    "def preprocess_data(data_list):\n",
    "    feature_list = []\n",
    "    for i in tqdm(range(len(data_list))):\n",
    "        feature_list.append(get_mfcc(data_list[i]))\n",
    "    return pd.DataFrame(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 동일한 이름의 폴더가 존재합니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(FOLDER_NAME)\n",
    "    print(f\"{FOLDER_NAME} 폴더가 성공적으로 생성되었습니다.\")\n",
    "except FileExistsError:\n",
    "    print(\"이미 동일한 이름의 폴더가 존재합니다.\")\n",
    "except Exception as e:\n",
    "    print(\"폴더 생성 중 오류가 발생했습니다:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv 파일을 불러옵니다.\n",
      "데이터 로드 완료\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  print(\"csv 파일을 불러옵니다.\")\n",
    "  train_data_feature = pd.read_csv(f'{FOLDER_NAME}/train_data_feature.csv')\n",
    "  test_data_feature = pd.read_csv(f'{FOLDER_NAME}/test_data_feature.csv')\n",
    "  \n",
    "  train_label = pd.read_csv(f'{FOLDER_NAME}/train_data_label.csv')\n",
    "  test_label = pd.read_csv(f'{FOLDER_NAME}/test_data_label.csv')\n",
    "except:\n",
    "  print(\"csv 파일을 생성합니다.\")\n",
    "  train_data, train_label = get_train_file()\n",
    "  test_data, test_label = get_test_file()\n",
    "\n",
    "  train_data_feature = preprocess_data(train_data)\n",
    "  test_data_feature = preprocess_data(test_data)\n",
    "  \n",
    "  train_data_feature.to_csv(f'{FOLDER_NAME}/train_data_feature.csv', index=False)\n",
    "  test_data_feature.to_csv(f'{FOLDER_NAME}/test_data_feature.csv', index=False)\n",
    "  \n",
    "  pd.DataFrame(train_label).to_csv(f'{FOLDER_NAME}/train_data_label.csv', index=False)\n",
    "  pd.DataFrame(test_label).to_csv(f'{FOLDER_NAME}/test_data_label.csv', index=False)\n",
    "else:\n",
    "  train_label = train_label.values.ravel()\n",
    "  test_label = test_label.values.ravel()\n",
    "finally:\n",
    "  print(\"데이터 로드 완료\")\n",
    "  train_data_label = np.array(train_label)\n",
    "  test_data_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 140)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_feature.shape\n",
    "test_data_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling for PCA\n",
    "scaler = StandardScaler()\n",
    "train_x_pca = scaler.fit_transform(train_data_feature)\n",
    "test_x_pca = scaler.fit_transform(test_data_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808\n"
     ]
    }
   ],
   "source": [
    "# Fit an SVM model\n",
    "clf = SVC(kernel='rbf', probability=True)\n",
    "clf.fit(train_x_pca, train_data_label)\n",
    "\n",
    "train_accuracy = accuracy_score(clf.predict(train_x_pca), train_data_label)\n",
    "print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9044444444444445\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(clf.predict(test_x_pca), test_data_label)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 원래 mfcc, nosie 추가\n",
    "0.9022222222222223\n",
    "\n",
    "2. 원래 mfcc, 음성 길이 증가\n",
    "0.7577777777777778\n",
    "\n",
    "3. 원래 mfcc, 음성 길이 감소\n",
    "0.7433333333333333\n",
    "\n",
    "4. 수정된 mfcc, noise 추가\n",
    "0.9022222222222223\n",
    "\n",
    "5. 수정된 mfcc\n",
    "0.9044444444444445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = open(f'202301ml_fmcc/fmcc_test_ref.txt', 'r')\n",
    "test_file_name = []\n",
    "\n",
    "for i in file_name.readlines():\n",
    "    file, _ = i.strip('\\n').split(' ')\n",
    "    test_file_name.append(file)\n",
    "\n",
    "def write_predictions(predictions, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for index, pred in enumerate(predictions):\n",
    "            file.write((f'{test_file_name[index]} ' + ('feml' if pred == 1 else 'male')) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = clf.predict(test_x_pca)\n",
    "write_predictions(test_predictions, f'202301ml_fmcc/{RESULTS_FILE_NAME}.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
